{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 : Real-world data representation using tensors\n",
    "\n",
    "### 1. Take several pictures of red, blue, and green items with your phone or other digital camera (or download some from the internet, if a camera isn’t available).\n",
    "* Load each image, and convert it to a tensor.\n",
    "* For each image tensor, use the `.mean()` method to get a sense of how bright the image is.\n",
    "* Take the mean of each channel of your images. Can you identify the red, green, and blue items from only the channel averages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T09:30:18.574100Z",
     "iopub.status.busy": "2021-08-08T09:30:18.573623Z",
     "iopub.status.idle": "2021-08-08T09:30:18.710678Z",
     "shell.execute_reply": "2021-08-08T09:30:18.709526Z",
     "shell.execute_reply.started": "2021-08-08T09:30:18.574068Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "main_path = \"data/\"\n",
    "redthing = \"red_thing.jpg\"\n",
    "greenthing = \"green_thing.jpg\"\n",
    "bluething = \"blue_thing.jpg\"\n",
    "\n",
    "img_red = Image.open(main_path+redthing)\n",
    "img_green = Image.open(main_path+greenthing)\n",
    "img_blue = Image.open(main_path+bluething)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T09:30:18.712564Z",
     "iopub.status.busy": "2021-08-08T09:30:18.712251Z",
     "iopub.status.idle": "2021-08-08T09:30:18.952127Z",
     "shell.execute_reply": "2021-08-08T09:30:18.950671Z",
     "shell.execute_reply.started": "2021-08-08T09:30:18.712533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape red image : torch.Size([3, 1024, 1024])\n",
      "shape green image : torch.Size([3, 338, 500])\n",
      "shape blue image : torch.Size([3, 682, 1023])\n",
      "\n",
      "\n",
      "mean red image : 0.235\n",
      "mean green image : 0.314\n",
      "mean blue image : 0.440\n"
     ]
    }
   ],
   "source": [
    "# There are many ways to convert an img into arrays/tensor. \n",
    "# Here we use torchvision to get used to it \n",
    "from torchvision import transforms\n",
    "\n",
    "preprocessor = transforms.ToTensor()\n",
    "red_t = preprocessor(img_red)\n",
    "green_t = preprocessor(img_green)\n",
    "blue_t = preprocessor(img_blue)\n",
    "\n",
    "print(f\"shape red image : {red_t.shape}\")\n",
    "print(f\"shape green image : {green_t.shape}\")\n",
    "print(f\"shape blue image : {blue_t.shape}\")\n",
    "print(\"\\n\")\n",
    "print(f\"mean red image : {red_t.mean():.3f}\")\n",
    "print(f\"mean green image : {green_t.mean():.3f}\")\n",
    "print(f\"mean blue image : {blue_t.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that each image has 3 channels : one for the RGB channel, and two for the sizes.\\\n",
    "Also, the red image seems to be the brighter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T09:30:18.955116Z",
     "iopub.status.busy": "2021-08-08T09:30:18.954589Z",
     "iopub.status.idle": "2021-08-08T09:30:18.962544Z",
     "shell.execute_reply": "2021-08-08T09:30:18.961433Z",
     "shell.execute_reply.started": "2021-08-08T09:30:18.955071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red channel : 0.616\n",
      "green channel : 0.024\n",
      "blue channel : 0.064\n"
     ]
    }
   ],
   "source": [
    "### Let's now look into the RGB channel of the red image\n",
    "print(f\"red channel : {red_t[0].mean():.3f}\")\n",
    "print(f\"green channel : {red_t[1].mean():.3f}\")\n",
    "print(f\"blue channel : {red_t[2].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T09:30:18.964670Z",
     "iopub.status.busy": "2021-08-08T09:30:18.964381Z",
     "iopub.status.idle": "2021-08-08T09:30:18.976346Z",
     "shell.execute_reply": "2021-08-08T09:30:18.975194Z",
     "shell.execute_reply.started": "2021-08-08T09:30:18.964642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red channel : 0.303\n",
      "green channel : 0.508\n",
      "blue channel : 0.130\n"
     ]
    }
   ],
   "source": [
    "### Let's now look into the RGB channel of the green image\n",
    "print(f\"red channel : {green_t[0].mean():.3f}\")\n",
    "print(f\"green channel : {green_t[1].mean():.3f}\")\n",
    "print(f\"blue channel : {green_t[2].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T09:30:18.978148Z",
     "iopub.status.busy": "2021-08-08T09:30:18.977824Z",
     "iopub.status.idle": "2021-08-08T09:30:18.990415Z",
     "shell.execute_reply": "2021-08-08T09:30:18.989480Z",
     "shell.execute_reply.started": "2021-08-08T09:30:18.978118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red channel : 0.231\n",
      "green channel : 0.410\n",
      "blue channel : 0.679\n"
     ]
    }
   ],
   "source": [
    "### Let's now look into the RGB channel of the blue image\n",
    "print(f\"red channel : {blue_t[0].mean():.3f}\")\n",
    "print(f\"green channel : {blue_t[1].mean():.3f}\")\n",
    "print(f\"blue channel : {blue_t[2].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, there is a dominance in the mean color channel respectively to each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Select a relatively large file containing Python source code.\n",
    "* Build an index of all the words in the source file (feel free to make your tokenization as simple or as complex as you like; we suggest starting with replacing `r\"[^a-zA-Z0-9_]+\"` with spaces).\n",
    "* Compare your index with the one we made for Pride and Prejudice. Which is larger?\n",
    "* Create the one-hot encoding for the source code file.\n",
    "* What information is lost with this encoding? How does that information compare to what’s lost in the Pride and Prejudice encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T09:30:18.992531Z",
     "iopub.status.busy": "2021-08-08T09:30:18.991880Z",
     "iopub.status.idle": "2021-08-08T09:30:19.005652Z",
     "shell.execute_reply": "2021-08-08T09:30:19.004566Z",
     "shell.execute_reply.started": "2021-08-08T09:30:18.992495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111177"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Loading a large file containing Python source code (2934 lines)\n",
    "with open(main_path + 'init_python_file.txt', encoding='utf8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T09:30:19.007566Z",
     "iopub.status.busy": "2021-08-08T09:30:19.007193Z",
     "iopub.status.idle": "2021-08-08T09:30:19.013234Z",
     "shell.execute_reply": "2021-08-08T09:30:19.012512Z",
     "shell.execute_reply.started": "2021-08-08T09:30:19.007535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\"Python Advanced Enumerations & NameTuples\"\"\"\\n\\nimport sys as _sys\\npyver = float(\\'%s.%s\\' % _sys.version_info[:2])\\n\\ntry:\\n    from collections import OrderedDict\\nexcept ImportError:\\n    OrderedDict = d'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print a sample of our file\n",
    "text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T09:30:19.015637Z",
     "iopub.status.busy": "2021-08-08T09:30:19.015137Z",
     "iopub.status.idle": "2021-08-08T09:30:19.038813Z",
     "shell.execute_reply": "2021-08-08T09:30:19.037717Z",
     "shell.execute_reply.started": "2021-08-08T09:30:19.015606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'advanced', 'enumerations', 'nametuples', 'import', 'sys', 'as', 'sys', 'pyver', 'float', 's', 's', 'sys', 'version', 'info', '2', 'try', 'from', 'collections', 'import', 'ordereddict', 'except', 'importerror', 'ordereddict', 'dict', 'from', 'collections', 'import', 'defaultdict', 'try', 'import', 'sqlite3', 'except', 'importerror', 'sqlite3', 'none', 'if', 'pyver', '3', 'from', 'functools', 'import', 'reduce', 'from', 'operator', 'import', 'or', 'as', 'or', 'and']\n",
      "\n",
      "len :  12637\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(input_text):\n",
    "    \"\"\"\n",
    "    Turns string caracters into list of words\n",
    "    input : string\n",
    "    output : list\n",
    "    \"\"\"\n",
    "    regex = r\"[^a-zA-Z0-9]+\"\n",
    "    text_clean = re.sub(regex, ' ', input_text)\n",
    "    text_clean = text_clean.lower().replace('\\n',' ')\n",
    "    word_list = text_clean.split()\n",
    "    return word_list\n",
    "\n",
    "word_list = preprocessor(text)\n",
    "print(word_list[:50])\n",
    "print(\"\\nlen : \", len(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've clear our text, let's build our own word One-Hot Encoding.\\\n",
    "This mean that each word will be represented by a vector of length equal to the number of different word in the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T09:30:19.040691Z",
     "iopub.status.busy": "2021-08-08T09:30:19.040365Z",
     "iopub.status.idle": "2021-08-08T09:30:19.052911Z",
     "shell.execute_reply": "2021-08-08T09:30:19.051863Z",
     "shell.execute_reply.started": "2021-08-08T09:30:19.040660Z"
    }
   },
   "outputs": [],
   "source": [
    "word_list = sorted(set(word_list)) # Left out duplicates and sort\n",
    "word2index_dict = {word: i for (i, word) in enumerate(word_list)} #Encoding each word with a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T09:30:19.054929Z",
     "iopub.status.busy": "2021-08-08T09:30:19.054305Z",
     "iopub.status.idle": "2021-08-08T09:30:19.078075Z",
     "shell.execute_reply": "2021-08-08T09:30:19.076964Z",
     "shell.execute_reply.started": "2021-08-08T09:30:19.054886Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([874, 874])\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor initialization\n",
    "word_t = torch.zeros(len(word_list), len(word2index_dict))\n",
    "\n",
    "# One-Hot Enconding\n",
    "for i, word in enumerate(word_list):\n",
    "    word_index = word2index_dict[word]\n",
    "    word_t[i][word_index] = 1\n",
    "    \n",
    "print(word_t.shape)\n",
    "print(word_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can discuss about what we just did and the purpuse of such encoding.\n",
    "\n",
    "First, the One-Hot word encoding (aka word-level encoding) provide a large sequence of words compare to character-level encoding. Indeed, there are significantly fewer characters than words and words provides much more meaning than individual character, but it comes with a price : the size of the sequence. On the other hand, dealing with a new word which is not in the sequence will raise issues since this One-Hot Encoding doesn't convey any dependency between two words.\\\n",
    "So, as a conclusion, for simple and basic text analysis, One-Hot Encoding may do the trick. But for advenced text analysis, there are more advanced ways to deal with words and characters that will provide fewer sequences and handling new appearance much better (see *byte pair encoding method* or *text embeddings method*) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
